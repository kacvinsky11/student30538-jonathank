{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"PSET 4\"\n",
        "author: \"Jonathan Kacvinsky\"\n",
        "date: \"02-07-2026\"\n",
        "format: \n",
        "  pdf:\n",
        "    include-in-header: \n",
        "       text: |\n",
        "         \\usepackage{fvextra}\n",
        "         \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n",
        "include-before-body:\n",
        "  text: |\n",
        "    \\RecustomVerbatimEnvironment{verbatim}{Verbatim}{\n",
        "      showspaces = false,\n",
        "      showtabs = false,\n",
        "      breaksymbolleft={},\n",
        "      breaklines\n",
        "    }\n",
        "output:\n",
        "  echo: false\n",
        "  eval: false\n",
        "---\n",
        "\n",
        "**Due 02/07 at 5:00PM Central.**\n",
        "\n",
        "\"This submission is my work alone and complies with the 30538 integrity policy.\" Add your initials to indicate your agreement: JK\n",
        "\n",
        "### Github Classroom Assignment Setup and Submission Instructions\n",
        "\n",
        "1.  **Accepting and Setting up the PS4 Assignment Repository**\n",
        "    -   Each student must individually accept the repository for the problem set from Github Classroom (\"ps4\") -- <https://classroom.github.com/a/hWhtcHqH>\n",
        "        -   You will be prompted to select your cnetid from the list in order to link your Github account to your cnetid.\n",
        "        -   If you can't find your cnetid in the link above, click \"continue to next step\" and accept the assignment, then add your name, cnetid, and Github account to this Google Sheet and we will manually link it: <https://rb.gy/9u7fb6>\n",
        "    -   If you authenticated and linked your Github account to your device, you should be able to clone your PS4 assignment repository locally.\n",
        "    -   Contents of PS4 assignment repository:\n",
        "        -   `ps4_template.qmd`: this is the Quarto file with the template for the problem set. You will write your answers to the problem set here.\n",
        "2.  **Submission Process**:\n",
        "    -   Knit your completed solution `ps4.qmd` as a pdf `ps4.pdf`.\n",
        "        -   Your submission does not need runnable code. Instead, you will tell us either what code you ran or what output you got.\n",
        "    -   To submit, push `ps4.qmd` and `ps4.pdf` to your PS4 assignment repository. Confirm on Github.com that your work was successfully pushed.\n",
        "\n",
        "### Grading\n",
        "- You will be graded on what was last pushed to your PS4 assignment repository before the assignment deadline\n",
        "- Problem sets will be graded for completion as: {missing (0%); ✓- (incomplete, 50%); ✓+ (excellent, 100%)}\n",
        "    - The percent values assigned to each problem denote how long we estimate the problem will take as a share of total time spent on the problem set, not the points they are associated with.\n",
        "- In order for your submission to be considered complete, you need to push both your `ps4.qmd` and `ps4.pdf` to your repository. Submissions that do not include both files will automatically receive 50% credit.\n",
        "\n",
        "\n",
        "\\newpage"
      ],
      "id": "8673d415"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import altair as alt\n",
        "import time\n",
        "import warnings \n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "alt.renderers.enable(\"png\")"
      ],
      "id": "651caa6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Develop initial scraper and crawler\n"
      ],
      "id": "814db165"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "url = 'https://oig.hhs.gov/fraud/enforcement/'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"lxml\")\n",
        "\n",
        "hhs_enf = []\n",
        "\n",
        "grid_col_fill = soup.find_all(\"div\", class_=\"grid-col-fill\")\n",
        "only_h2 = None\n",
        "for div in grid_col_fill:\n",
        "    if div.find(\"h2\"):\n",
        "        only_h2 = div\n",
        "        break\n",
        "\"\"\"finds correct grid_col_fill out of many\"\"\"\n",
        "enf_act = only_h2.find_all(\"h2\")\n",
        "\n",
        "for category in enf_act:\n",
        "    \n",
        "    enf_category = category.get_text(strip=True)\n",
        "    ul = category.find_next(\"ul\")\n",
        "\n",
        "    if not ul:\n",
        "        continue\n",
        "\n",
        "    for li in ul.find_all(\"li\"):\n",
        "        \"\"\"iterates and parses each li\"\"\"\n",
        "        link = li.find(\"a\")\n",
        "        if not link:\n",
        "            continue\n",
        "        \"\"\"necessary because not all li's contain a's\"\"\"\n",
        "\n",
        "        enf_title = link.get_text(strip=True)\n",
        "\n",
        "        date_tag = li.find(\"span\")\n",
        "        enf_date = date_tag.get_text(strip=True) if date_tag else None\n",
        "        \"\"\"only takes date tag if exists in li\"\"\"\n",
        "        \n",
        "        enf_url = link[\"href\"]\n",
        "\n",
        "        hhs_enf.append({\n",
        "            \"title\": enf_title,\n",
        "            \"date\": enf_date,\n",
        "            \"category\": enf_category,\n",
        "            \"link\": enf_url\n",
        "        })\n",
        "\n",
        "hhs = pd.DataFrame(hhs_enf)\n",
        "hhs.head()"
      ],
      "id": "f4439028",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Making the scraper dynamic\n",
        "\n",
        "### 1. Turning the scraper into a function \n",
        "\n",
        "* a. Pseudo-Code\n",
        "\n",
        "Define a function named dynamic_scraper with inputs (month, year, scrape)\n",
        "Create an indicator with an if function, where if scrape is false then a pop-up will tell us the \"Function not run\" then EXIT the function\n",
        "To ensure we restrict year to >= 2013 we write another if function where if year < 2013: message is printed \"Year is less than 2013\" then EXIT function\n",
        "Store scraped actions by initializing variables like current_year = year, current_month = month, today = datetime.today(), today_year = today.year, today_month = today.month, then store it in a list like hhs_crawl = []\n",
        "To enhance our for loop from step 1, we can use while to ensure we crawl up years with while (current_year < today_year): print (f\"Scraping {current_year}-{current_month}\")\n",
        "To get our url we can set url - f\"url of year {current_year} and month = {current_month}\" and use:\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"lxml\")\n",
        "from step 1.\n",
        "Continue with function from step 1 until we need to pause a second before crawling, using time.sleep(1)\n",
        "To increment by month we can use an if function with if current_month == 12: current_month = 1 current_year += 1 else: current_month += 1 to move up to the next year once we hit December\n",
        "Store into a dataframe then make into a csv using to_csv()\n",
        "\n",
        "\n",
        "* b. Create Dynamic Scraper"
      ],
      "id": "408bc578"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def dynamic_scraper(year, month, scraper=True):\n",
        "\n",
        "    if not scraper:\n",
        "        print(\"Function not run\")\n",
        "        return None\n",
        "    \n",
        "    original_url = \"https://oig.hhs.gov/fraud/enforcement/\"\n",
        "    page = 0\n",
        "    hhs_crawl = []\n",
        "\n",
        "    today = datetime(year, month, 1)\n",
        "\n",
        "\n",
        "    while True:\n",
        "        url = f\"{original_url}?page={page}\"\n",
        "        print(f\"Currently Scraping Page {page}\")\n",
        "        \n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, \"lxml\")\n",
        "\n",
        "        grid_col_fill = soup.find_all(\"div\", class_=\"grid-col-fill\")\n",
        "        only_h2 = None\n",
        "\n",
        "        for div in grid_col_fill:\n",
        "            if div.find(\"h2\"):\n",
        "                only_h2 = div\n",
        "                break\n",
        "        \n",
        "        if not only_h2:\n",
        "            print(\"No enforcement section found\")\n",
        "            break\n",
        "        \n",
        "        enf_act = only_h2.find_all(\"h2\")\n",
        "        page_items = 0\n",
        "\n",
        "        for category in enf_act:\n",
        "            enf_category = category.get_text(strip=True)\n",
        "            ul = category.find_next(\"ul\")\n",
        "\n",
        "            if not ul:\n",
        "                continue\n",
        "\n",
        "            for li in ul.find_all(\"li\"):\n",
        "                link = li.find(\"a\")\n",
        "                if not link:\n",
        "                    continue\n",
        "\n",
        "                enf_title = link.get_text(strip=True)\n",
        "                url_crawl = urljoin(original_url, link[\"href\"])\n",
        "\n",
        "                date_tag = li.find(\"span\")\n",
        "                enf_date = date_tag.get_text(strip=True) if date_tag else None\n",
        "\n",
        "                try:\n",
        "                    action_date = datetime.strptime(enf_date, \"%B %d, %Y\")\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "                if action_date < today:\n",
        "                    continue\n",
        "\n",
        "                hhs_crawl.append({\n",
        "                    \"title\": enf_title,\n",
        "                    \"date\": action_date.strftime(\"%Y-%m-%d\"),\n",
        "                    \"category\": enf_category,\n",
        "                    \"link\": url_crawl\n",
        "                })\n",
        "\n",
        "                page_items += 1\n",
        "\n",
        "        if page_items == 0:\n",
        "            print(\"No enforcement actions found\")\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "\n",
        "    hhs_dynamic = pd.DataFrame(hhs_crawl)\n",
        "    hhs_dynamic.to_csv(f\"enforcement_actions_{year}_{month:02d}.csv\", index=False)\n",
        "    return hhs_dynamic\n",
        "\n",
        "jan_2024 = dynamic_scraper(2024, 1, True)\n",
        "jan_2024.head()\n",
        "jan_2024"
      ],
      "id": "e0191e64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#520 entries, with the earliest date being January 27,2026\n",
        "\n",
        "\n",
        "* c. Test Your Code"
      ],
      "id": "de84296f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "jan_2022 = dynamic_scraper(2022, 1, True)\n",
        "jan_2022.head()"
      ],
      "id": "13b911c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Plot data based on scraped data\n",
        "\n",
        "### 1. Plot the number of enforcement actions over time"
      ],
      "id": "fadc4b05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "enf_act_2022 = pd.read_csv(\"enforcement_actions_2022_01.csv\")\n",
        "enf_act_2022[\"date\"] = pd.to_datetime(enf_act_2022[\"date\"])\n",
        "\n",
        "month_count = (enf_act_2022.assign(month=enf_act_2022[\"date\"].dt.to_period(\"M\"))\n",
        "               .groupby(\"month\")\n",
        "               .size()\n",
        "               .reset_index(name=\"num_actions\")\n",
        ")\n",
        "month_count[\"month\"] = month_count[\"month\"].dt.to_timestamp()\n",
        "\n",
        "graph_1 = (alt.Chart(month_count).mark_line(point=True).encode(\n",
        "    alt.X(\"month:T\", title=\"Month\", axis = alt.Axis(format=\"%b %Y\", labelAngle=-70)\n",
        "    ),\n",
        "    alt.Y(\"num_actions:Q\", title=\"Number of Enforcement Actions\"\n",
        "    ),\n",
        "    tooltip=[\n",
        "        alt.Tooltip(\"month:T\", title=\"Month\", format=\"%B %Y\"),\n",
        "        alt.Tooltip(\"num_actions:Q\", title=\"Actions\")\n",
        "    ]\n",
        ")\n",
        ".properties(\n",
        "    title = \"HHS OIG Enforcement Actions Per Month Since January 2022\",\n",
        "    width=500,\n",
        "    height=500\n",
        ")\n",
        ")\n",
        "\n",
        "graph_1"
      ],
      "id": "1431744a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Plot the number of enforcement actions categorized:\n",
        "\n",
        "* based on \"Criminal and Civil Actions\" vs. \"State Enforcement Agencies\""
      ],
      "id": "3402cf85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "month_type_count = (\n",
        "    enf_act_2022\n",
        "    .groupby([\"month\", \"enforcement_type\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"num_actions\")\n",
        "    )\n",
        "\n",
        "graph_2 = (alt.Chart(month_type_count).mark_line(point=True).encode(\n",
        "    alt.X(\"month:T\", title=\"Month\", axis = alt.Axis(format=\"%b %Y\", labelAngle=-70)\n",
        "    ),\n",
        "    alt.Y(\"num_actions:Q\", title=\"Number of Enforcement Actions\"\n",
        "    ),\n",
        "    color=alt.Color(\"enforcement_type:N\", title=\"Enforcement Types\"\n",
        "    ),\n",
        "    tooltip=[\n",
        "        alt.Tooltip(\"month:T\", title=\"Month\", format=\"%B %Y\"),\n",
        "        alt.Tooltip(\"num_actions:Q\", title=\"Actions\"),\n",
        "        alt.Tooltip(\"enforcement_type:N\", title=\"Type\")\n",
        "    ]\n",
        ")\n",
        ".properties(\n",
        "    title = \"HHS OIG Enforcement Actions Per Month Since January 2022 by Type\",\n",
        "    width=500,\n",
        "    height=500\n",
        ")\n",
        ")\n",
        "\n",
        "graph_2"
      ],
      "id": "2cbfd394",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* based on five topics"
      ],
      "id": "45743f54"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "graph_3 = (alt.Chart(month_topic_count).mark_line(point=True).encode(\n",
        "    alt.X(\"month:T\", title=\"Month\", axis = alt.Axis(format=\"%b %Y\", labelAngle=-70)\n",
        "    ),\n",
        "    alt.Y(\"num_actions:Q\", title=\"Number of Enforcement Actions\"\n",
        "    ),\n",
        "    color=alt.Color(\"topic:N\", title=\"Enforcement Topics\"\n",
        "    ),\n",
        "    tooltip=[\n",
        "        alt.Tooltip(\"month:T\", title=\"Month\", format=\"%B %Y\"),\n",
        "        alt.Tooltip(\"num_actions:Q\", title=\"Actions\"),\n",
        "        alt.Tooltip(\"enforcement_type:N\", title=\"Type\")\n",
        "    ]\n",
        ")\n",
        ".properties(\n",
        "    title = \"HHS OIG Enforcement Actions Per Month Since January 2022 by Topic\",\n",
        "    width=500,\n",
        "    height=500\n",
        ")\n",
        ")\n",
        "\n",
        "graph_3"
      ],
      "id": "168cc7d6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "c:\\Users\\home-admin\\Documents\\Python\\envs\\DAP\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}